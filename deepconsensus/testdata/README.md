## DeepConsensus Test Data

**New test data setup**

With the pipeline moving to a pysam based approach, new test data is needed.
This test data can be generated by running generate_testdata.sh in this
directory.

*   `human_1m` - Derived from a human_1m dataset
*   `preprocess` - Simple toy datasets for testing preprocessing.

**Old test data setup**

To regenerate the files under `learning/genomics/deepconsensus/testdata`, run
the below command. You will need to do this if you have modified the data
processing code in a way that changes the outputs from each Beam pipeline
(`merge_datasets`, `generate_input`, `write_tf_examples`).

```
time ./learning/genomics/deepconsensus/scripts/generate_testdata.sh
```

This command should take ~6 min to complete.

## testdata/model

Generated with:

```bash
MODEL=transformer_learn_values
CONFIG="//learning/genomics/deepconsensus/models/model_configs.py:${MODEL}+test"
TEMP_MODEL_DIR="/tmp/deepconsensus/model/$(TZ=US/Pacific date '+%Y%m%d%H%M%S')"
MODEL_TRAIN_COMMAND="time blaze run -c opt \\
//learning/genomics/deepconsensus/models:model_train_custom_loop -- \\
  --params ${CONFIG} \\
  --out_dir ${TEMP_MODEL_DIR} \\
  --write_checkpoint_metrics" \

eval "${MODEL_TRAIN_COMMAND}"

MODEL_DIR="learning/genomics/deepconsensus/testdata/model"
mkdir -p "${MODEL_DIR}"
cp "${TEMP_MODEL_DIR}"/checkpoint* "${MODEL_DIR}"
```

